{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airports_fname = 'data/PrediqtAirports.csv'\n",
    "training_fname = 'data/PrediqtTrainData.csv'\n",
    "\n",
    "out_training = 'my_data/training.csv'\n",
    "out_validation = 'my_data/validation.csv'\n",
    "out_test = 'my_data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATITUDE\n",
      "LONGITUDE\n"
     ]
    }
   ],
   "source": [
    "with open(airports_fname, 'r') as f:\n",
    "    airports = pandas.read_csv(airports_fname)\n",
    "for key in ('LATITUDE', 'LONGITUDE'):\n",
    "    print key\n",
    "    airports[key] = airports[key].apply(math.radians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ONE_DAY = 60 * 60 * 24\n",
    "\n",
    "BINS = {}\n",
    "BINS['PRICE'] = (\n",
    "    0.0, 42.18, 54.600000000000001, 65.359999999999999, \n",
    "    75.280000000000001, 84.540000000000006, 93.620000000000005, \n",
    "    101.38, 109.23, 117.3, 124.98, 132.22, 139.58000000000001, \n",
    "    145.97999999999999, 151.97999999999999, 158.28999999999999, \n",
    "    163.84999999999999, 169.80000000000001, 174.24000000000001, \n",
    "    179.97999999999999, 185.36000000000001, 190.19, 195.62, \n",
    "    199.97999999999999, 204.97999999999999, 209.97999999999999, \n",
    "    215.34, 219.97999999999999, 225.08000000000001, 229.97999999999999, \n",
    "    235.36000000000001, 239.97999999999999, 245.40000000000001, 250.0, \n",
    "    256.05000000000001, 260.98000000000002, 268.86000000000001, 273.87, \n",
    "    279.98000000000002, 287.75999999999999, 294.49000000000001, \n",
    "    300.98000000000002, 309.98000000000002, 319.26999999999998, \n",
    "    326.98000000000002, 335.69, 343.48000000000002, 353.5, \n",
    "    362.98000000000002, 374.48000000000002, 385.13999999999999, \n",
    "    397.82999999999998, 409.98000000000002, 423.30000000000001, \n",
    "    437.98000000000002, 451.60000000000002, 466.51999999999998, 480.87, \n",
    "    496.33999999999997, 510.24000000000001, 526.02999999999997, \n",
    "    539.98000000000002, 550.28999999999996, 568.98000000000002, \n",
    "    579.98000000000002, 599.46000000000004, 612.47000000000003, \n",
    "    629.98000000000002, 648.98000000000002, 664.0, 679.98000000000002, \n",
    "    699.09000000000003, 709.98000000000002, 727.07000000000005, \n",
    "    739.98000000000002, 756.72000000000003, 769.98000000000002, \n",
    "    786.98000000000002, 799.98000000000002, 810.92999999999995, \n",
    "    825.08000000000004, 833.80999999999995, 848.0, 856.07000000000005, \n",
    "    867.98000000000002, 874.73000000000002, 886.16999999999996, \n",
    "    896.10000000000002, 902.10000000000002, 909.98000000000002, \n",
    "    919.98000000000002, 929.98000000000002, 939.98000000000002, \n",
    "    949.98000000000002, 959.98000000000002, 969.98000000000002, \n",
    "    979.98000000000002, 989.98000000000002, 999.98000000000002, 1009.98, \n",
    "    1019.98, 1029.98, 1039.98, 1049.98, 1061.98, 1073.29, 1081.23, \n",
    "    1091.98, 1103.5, 1115.98, 1127.98, 1138.49, 1149.98, 1161.98, \n",
    "    1175.98, 1188.98, 1199.98, 1216.4300000000001, 1229.98, 1245.98, \n",
    "    1259.98, 1277.0899999999999, 1289.98, 1307.98, 1319.98, 1339.98, \n",
    "    1359.98, 1379.98, 1399.98, 1419.98, 1440.98, 1462.98, 1489.98, \n",
    "    1519.98, 1554.98, 1589.98, 1639.98, 1699.98, 1778.98, 1886.98, \n",
    "    2052.98, 10099.838400000001)\n",
    "BINS['STI'] = (  \n",
    "    0.00000000e+00,   3.00000000e+00,   4.00000000e+00,\n",
    "    7.00000000e+00,   9.00000000e+00,   1.20000000e+01,\n",
    "    1.50000000e+01,   1.90000000e+01,   2.40000000e+01,\n",
    "    3.30000000e+01,   1.71990000e+04)\n",
    "BINS['STO'] = ( \n",
    "    -1.68070000e+04,   1.50000000e+01,   2.90000000e+01,\n",
    "    4.30000000e+01,   6.10000000e+01,   8.10000000e+01,\n",
    "    1.12000000e+02,   1.46000000e+02,   1.80000000e+02,\n",
    "    2.15000000e+02,   4.37000000e+02)\n",
    "BINS['OTI'] = (-2.,  27.,  43.,  60.,  79.,  99., 131., 166., 202., 235., 451.)\n",
    "\n",
    "MOST_COMMON = {}\n",
    "MOST_COMMON['MARKETS'] = (\n",
    "    '**', 'UK', 'US', 'FR', 'IT', 'DE', 'ES', 'SK', 'TR', 'AT', 'PT', 'PL', \n",
    "    'RU', 'IE', 'HU', 'CZ', 'GR', 'BR', 'BG', 'NL', 'RO', 'CH', 'TW', 'HK', \n",
    "    'MT', 'IL', 'BE', 'SA', 'CA', 'KW', 'MO', 'SI', 'QA', 'KZ', 'BH', 'OM', \n",
    "    'IS', 'BY', 'GE', 'ME', 'MD', 'LB', 'AZ', 'AD', 'SM', 'VA', 'HR', 'LI', \n",
    "    'BA', 'GL', 'FO', 'MK', 'KO', 'BV', 'MN', 'LU', 'WF', 'TF', 'BN', 'WS', \n",
    "    'GU', 'PW', 'PG', 'PN', 'SB', 'MP', 'FJ', 'FM', 'VU', 'NU', 'CK', 'CC', \n",
    "    'CX', 'KH', 'TV', 'TO', 'TL', 'TK', 'AS', 'LK', 'MV', 'BT', 'BQ', 'GS', \n",
    "    'HM', 'MH', 'UM', 'MS', 'NF', 'CW', 'SX', 'KI', 'SJ', 'LA', 'AN', 'AQ', \n",
    "    'IO', 'MC', 'RS')\n",
    "MOST_COMMON['ORIGIN'] = (\n",
    "    'MAN', 'LHR', 'FRA', 'LGW', 'CDG', 'AMS', 'MAD', 'BHX', 'DUS', 'MUC', \n",
    "    'STN', 'MXP', 'BRU', 'GLA', 'SVO', 'FCO', 'HAM', 'BCN', 'GRU', 'IST', \n",
    "    'GIG', 'ZRH', 'MEX', 'STR', 'CGN', 'EMA', 'YYZ', 'DUB', 'CUN', 'TXL', \n",
    "    'DME', 'CPH', 'NCL', 'ATH', 'VCE', 'VIE', 'LIS', 'LAX', 'WAW', 'BUD', \n",
    "    'GVA', 'BLQ', 'LED', 'HAJ', 'LIN', 'BRS', 'EDI', 'JFK', 'HEL', 'PRG', \n",
    "    'ORY', 'ARN', 'LBA', 'SFO', 'EZE', 'LPL', 'OSL', 'SXF', 'BIO', 'MSP', \n",
    "    'OPO', 'LYS', 'TFS', 'IAH', 'DFW', 'BOG', 'BWI', 'BLL', 'MRS', 'RIX', \n",
    "    'BSL', 'PDX', 'TLL', 'BSB', 'LTN', 'SJO', 'SEA', 'BKK', 'TLV', 'VCP', \n",
    "    'OAK', 'POA', 'PMI', 'VNO', 'SOF', 'SIN', 'SCL', 'BGY', 'AYT', 'LEJ', \n",
    "    'REC', 'AAL', 'TLS', 'YUL', 'NCE', 'LJU', 'CNF', 'MCO', 'FOR', 'YVR', \n",
    "    'LAS', 'KBP', 'FLR', 'BEG', 'LCA', 'BRE', 'OTP', 'ZAG', 'BFS', 'CWL', \n",
    "    'CPT', 'SJC', 'KRK', 'DEN', 'BUR', 'TRN', 'BOS', 'JED', 'ORD', 'VRN', \n",
    "    'JNB', 'SKG', 'AGP', 'GOT', 'SSA', 'LIM', 'GDL', 'CCS', 'HAV', 'NAP', \n",
    "    'ONT', 'CAI', 'SYD', 'PHX', 'LCY', 'NUE', 'AUS', 'CWB', 'ISP', 'FLL', \n",
    "    'MEL', 'EIN', 'EWR', 'SNA', 'HER', 'ALC', 'DLM', 'SAN', 'SDQ')\n",
    "MOST_COMMON['DESTINATION_COUNTRY'] = (\n",
    "    'ES', 'US', 'CU', 'TH', 'UK', 'BR', 'TR', 'DE', 'MX', 'IT', 'GR', 'CA', \n",
    "    'DO', 'ZA', 'FR', 'PT', 'CR', 'NL', 'MU', 'MV', 'AR', 'RU', 'CY', 'IN', \n",
    "    'KE', 'PE', 'CH', 'CO', 'AU', 'EG', 'IE', 'SG', 'PL', float('NaN'), 'AE',\n",
    "    'TZ', 'JP', 'AT', 'CL', 'JM', 'EC', 'BE', 'BB', 'CZ', 'PA', 'PH', 'ID', \n",
    "    'HU', 'CN')\n",
    "MOST_COMMON['ORIGIN_COUNTRY'] = (\n",
    "    'UK', 'DE', 'US', 'IT', 'ES', 'FR', 'BR', 'RU', 'NL', 'MX', 'BE', 'CH', \n",
    "    'CA', 'TR', 'DK', 'PL', 'GR', 'PT', 'IE', 'AT', 'SE', 'HU', 'FI', 'AR')\n",
    "MOST_COMMON['DESTINATION'] = (\n",
    "    'HAV', 'PMI', 'TFS', 'BKK', 'CUN', 'GIG', 'MCO', 'LAS', 'JFK', 'MAD', \n",
    "    'HKT', 'DLM', 'FRA', 'LHR', 'CPT', 'SJO', 'PUJ', 'MRU', 'LAX', 'BCN', \n",
    "    'YYZ', 'ACE', 'MLE', 'AYT', 'CDG', 'LPA', 'AMS', 'VRA', 'EZE', 'FUE', \n",
    "    'LIS', 'SFO', 'FCO', 'MAN', 'LGW', 'IBZ', 'LIM', 'HER', 'MEX', 'GRU', \n",
    "    'SDQ', 'LCA', 'SIN', 'IST', 'JNB', 'STN', 'WDH', 'DUB', 'ATH', 'ALC', \n",
    "    'MUC', 'MXP', 'BOG', 'AGP', 'NBO', 'SCL', 'MBJ', 'BGI', 'HNL', 'ZNZ', \n",
    "    'YUL', 'FAO', 'PTY', 'YVR', 'PRG', 'MAH', 'SEA', 'BUD', 'CFU', 'DXB', \n",
    "    'MBA', 'TXL', 'BRU', 'MIA', 'OPO', 'GVA', 'PFO', 'HRG', 'ZRH', 'ZTH', \n",
    "    'UIO', 'VIE', 'CPH', 'MNL', 'POP', 'BWI', 'MSP', 'HOG', 'FOR', 'DUS', \n",
    "    'DPS', 'DFW', 'GUA', 'IAH', 'MGA', 'EDI', 'SXF', 'NRT', 'SEZ', 'TLV', \n",
    "    'DEN', 'SYD', 'RHO', 'SVO', 'MEL', 'HKG', 'VCE', 'CAI', 'SAN', 'GLA', \n",
    "    'PNH', 'ARN', 'CGN', 'PDX', 'FLL', 'DEL', 'DME', 'BHX', 'PRN', 'FLR', \n",
    "    'EWR', 'KRK', 'SSA', 'GOI', 'BUR', 'OSL', 'SJU', 'BJL', 'PBI', 'SKG', \n",
    "    'LED', 'HAM', 'OAK', 'KUL', 'SOF', 'LIN', 'RTM', 'CMB', 'PHX', 'RAK', \n",
    "    'REC', 'BLQ', 'ICN', 'NCE', 'EIN', 'BOS', 'BGY', 'SJC', 'SNA', 'MJV', \n",
    "    'MLA', 'XRY', 'ORY', 'HEL', 'TFN', 'CTG', 'KEF', 'GYE', 'SGN', 'ORD', \n",
    "    'NAP', 'CCS', 'ONT', 'WAW', 'YYC', 'BSL', 'VCP', 'LYS', 'SLC', 'CIA', \n",
    "    'OTP', 'AKL', 'STR', 'BEG', 'SAL', 'BOM', 'BSB', 'BIO', 'RGN', 'SAW', \n",
    "    'MVD', 'KBP', 'VLC', 'DBV', 'SVQ', 'NAT', 'GRX', 'DUR', 'RUN', 'TRN', \n",
    "    'MRS', 'AUS', 'SSH', 'PSA', 'CNF', 'JTR', 'YQB', 'ZAG', 'KBV', 'PEK', \n",
    "    'RIX', 'JED', 'FNC', 'PVG', 'POA', 'TPE', 'KGS', 'LGA', 'ADB', 'BVA', \n",
    "    'REU', 'TLS', 'AER', 'ISB', 'GDL', 'ATL', 'AGA', 'CTA', 'CNX', 'BJV', \n",
    "    'LTN', 'BOJ', 'PER', 'VNO')\n",
    "\n",
    "MAX = {}\n",
    "MAX['TRAFFIC'] = 17435204.0\n",
    "MAX['ORIGIN_LATITUDE'] = 1.51305442978\n",
    "MAX['ORIGIN_LONGITUDE'] = 3.14744823323\n",
    "MAX['DESTINATION_LATITUDE'] = 1.51305442978\n",
    "MAX['DESTINATION_LONGITUDE'] = 3.16145255339\n",
    "MAX['DISTANCE'] = 20141.4607366\n",
    "\n",
    "MIN = {}\n",
    "MIN['TRAFFIC'] = 0.0\n",
    "MIN['ORIGIN_LATITUDE'] = -0.966767766679\n",
    "MIN['ORIGIN_LONGITUDE'] = -3.10543525513\n",
    "MIN['DESTINATION_LATITUDE'] = -0.966767766679\n",
    "MIN['DESTINATION_LONGITUDE'] = -3.17083736087\n",
    "MIN['DISTANCE'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert(num, buckets, bucket_ranges=None,):\n",
    "    \"\"\"go from 0..1 to larger\"\"\"\n",
    "    buckets = tuple(buckets)\n",
    "    if bucket_ranges is None:\n",
    "        bucket_ranges = itertools.izip(buckets, buckets[1:])\n",
    "    step = 1 / float(len(buckets))\n",
    "    cumsum = 0\n",
    "    for low, high in bucket_ranges:\n",
    "        if cumsum <= num < cumsum + step:\n",
    "            t = (num - cumsum) / step\n",
    "            return (1 - t) * low + t * high\n",
    "        cumsum += step\n",
    "    t = (num - (cumsum - step)) / step\n",
    "    return (1 - t) * low + t * high\n",
    "\n",
    "def reverse_convert(num, bin_key, _range=range(12), cache={}):\n",
    "    \"\"\"go from larger to 0..1\"\"\"\n",
    "    key = (num, bin_key)\n",
    "    try:\n",
    "        return cache[key]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    # Binary search, because I couldn't spend time to figure it out properly... oh well\n",
    "    buckets = BINS[bin_key]\n",
    "    bucket_ranges = zip(buckets, buckets[1:])\n",
    "    high, low = 0., 1.\n",
    "    for __ in _range:\n",
    "        mid = (high + low) / 2.\n",
    "        result = convert(mid, buckets=buckets, bucket_ranges=bucket_ranges)\n",
    "        if abs(result - num) < 0.001:\n",
    "            break\n",
    "        if result > num:\n",
    "            low = mid\n",
    "        else:\n",
    "            high = mid\n",
    "            \n",
    "    cache[key] = mid\n",
    "    return mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_onehot(values, field, onehot=None, cache={}):\n",
    "    values = values.split(';')\n",
    "    key = (tuple(values), field)\n",
    "    try:\n",
    "        return cache[key]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    most_common = MOST_COMMON[field]\n",
    "    if onehot is None:\n",
    "        #zeros_size = len(most_common) + (1 if excluded > 0 else 0)\n",
    "        zeros_size = len(most_common) + (1)\n",
    "        onehot = np.zeros((zeros_size,), dtype='bool')\n",
    "    most_common_index = most_common.index\n",
    "    for value in values:\n",
    "        try:\n",
    "            onehot[most_common_index(value)] = True\n",
    "        except ValueError:\n",
    "            onehot[zeros_size - 1] = True\n",
    "    cache[key] = onehot\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sin, cos, sqrt, atan2, radians = math.sin, math.cos, math.sqrt, math.atan2, math.radians\n",
    "def distance(lat1, lon1, lat2, lon2, cache={}):\n",
    "    key = (lat1, lon1, lat2, lon2)\n",
    "    try:\n",
    "        return cache[key]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    # Haversine\n",
    "    delta_phi = lat2 - lat1\n",
    "    delta_lambda = lon2 - lon1\n",
    "    \n",
    "    sdp2 = sin(delta_phi / 2.)\n",
    "    sdl2 = sin(delta_lambda / 2.)\n",
    "    a = sdp2 ** 2 + cos(lat1) * cos(lat2) * sdl2 ** 2\n",
    "    dist = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    \n",
    "    dist *= 0.31631270856  # shh\n",
    "    cache[key] = dist\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot_encode_date(date):\n",
    "    array = np.zeros((7 + 12 + 31,), dtype='bool')\n",
    "    array[date.weekday() - 1] = True\n",
    "    array[date.month + 7 - 1] = True\n",
    "    array[date.day + 7 + 12 - 1] = True\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lerp(value, field):\n",
    "    minimum = MIN[field]\n",
    "    return (value - minimum) / (MAX[field] - minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "radians = math.radians\n",
    "def convert_row(row):\n",
    "    outbound_dt = datetime.strptime(row['OUTBOUND_DATE'], '%Y-%m-%d')\n",
    "    inbound_dt = datetime.strptime(row['INBOUND_DATE'], '%Y-%m-%d')\n",
    "    search_dt = datetime.strptime(row['SEARCH_DATEHOUR'], '%Y-%m-%dT%H:%M:%S')\n",
    "    outbound_date = onehot_encode_date(outbound_dt)\n",
    "    inbound_date = onehot_encode_date(inbound_dt)\n",
    "    \n",
    "    sto = (outbound_dt - search_dt).total_seconds() / ONE_DAY\n",
    "    sti = (inbound_dt - search_dt).total_seconds() / ONE_DAY\n",
    "    oti = (inbound_dt - outbound_dt).total_seconds() / ONE_DAY\n",
    "    search_to_outbound = reverse_convert(sto, 'STO')\n",
    "    search_to_inbound = reverse_convert(sti, 'STI')\n",
    "    outbound_to_inbound = reverse_convert(oti, 'OTI')\n",
    "    \n",
    "    markets = make_onehot(row['MARKETS'], 'MARKETS')\n",
    "    \n",
    "    row_origin = row['ORIGIN']\n",
    "    origin = make_onehot(row_origin, 'ORIGIN')\n",
    "    origin_data = airports[airports.AIRPORT == row_origin]\n",
    "    origin_country = make_onehot(next(iter(origin_data['COUNTRY'])), 'ORIGIN_COUNTRY')\n",
    "    origin_traffic = lerp(float(origin_data['TRAFFIC']), 'TRAFFIC')\n",
    "    \n",
    "    origin_latitude_rads = radians(float(origin_data['LATITUDE']))\n",
    "    origin_longitude_rads = radians(float(origin_data['LONGITUDE']))\n",
    "    origin_latitude = lerp(origin_latitude_rads, 'ORIGIN_LATITUDE')\n",
    "    origin_longitude = lerp(origin_longitude_rads, 'ORIGIN_LONGITUDE')\n",
    "    \n",
    "    row_destination = row['DESTINATION']\n",
    "    destination = make_onehot(row_destination, 'DESTINATION')\n",
    "    destination_data = airports[airports.AIRPORT == row_destination]\n",
    "    destination_country = make_onehot(str(next(iter(destination_data['COUNTRY']))), 'DESTINATION_COUNTRY')\n",
    "    destination_traffic = lerp(float(destination_data['TRAFFIC']), 'TRAFFIC')\n",
    "    \n",
    "    destination_latitude_rads = radians(float(destination_data['LATITUDE']))\n",
    "    destination_longitude_rads = radians(float(destination_data['LONGITUDE']))\n",
    "    destination_latitude = lerp(destination_latitude_rads, 'DESTINATION_LATITUDE')\n",
    "    destination_longitude = lerp(destination_longitude_rads, 'DESTINATION_LONGITUDE')\n",
    "    \n",
    "    dist = distance(\n",
    "        origin_latitude_rads, origin_longitude_rads, \n",
    "        destination_latitude_rads, destination_longitude_rads\n",
    "    )\n",
    "    \n",
    "    price = reverse_convert(float(row['PRICE']), 'PRICE')\n",
    "    \n",
    "    return np.concatenate((\n",
    "        outbound_date, inbound_date,\n",
    "        markets,\n",
    "        origin, origin_country,\n",
    "        destination, destination_country,\n",
    "        [search_to_outbound, search_to_inbound, outbound_to_inbound,\n",
    "         origin_traffic, destination_traffic,\n",
    "         origin_latitude, origin_longitude, destination_latitude, destination_longitude,\n",
    "         dist, price]\n",
    "    ))\n",
    "    # return concatenation of values, arrays (as comma-separated string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "5000\n",
      "7500\n",
      "10000\n",
      "12500\n",
      "15000\n",
      "17500\n",
      "20000\n",
      "22500\n",
      "25000\n",
      "27500\n",
      "30000\n",
      "32500\n",
      "35000\n",
      "37500"
     ]
    }
   ],
   "source": [
    "comma_join = ','.join\n",
    "with open(training_fname, 'r') as f, open(out_training, 'w') as train, open(out_validation, 'w') as valid, open(out_test, 'w') as test:\n",
    "    COLUMNS = next(f).strip().split(',')\n",
    "    train_l, valid_l, test_l = [], [], []\n",
    "    for i, line in enumerate(f):\n",
    "        converted = convert_row(dict(itertools.izip(COLUMNS, line.strip().split(','))))\n",
    "        r = random.random()\n",
    "        if r <= 0.8:\n",
    "            write = train_l.append\n",
    "        elif r <= 0.9:\n",
    "            write = valid_l.append\n",
    "        else:\n",
    "            write = test_l.append\n",
    "        write(comma_join(map(str, converted)))\n",
    "        if not (i + 1) % 2500:\n",
    "            print (i + 1)\n",
    "            train.write('\\n'.join(train_l) + '\\n')\n",
    "            valid.write('\\n'.join(valid_l) + '\\n')\n",
    "            test.write('\\n'.join(test_l) + '\\n')\n",
    "            train_l, valid_l, test_l = [], [], []\n",
    "    train.write('\\n'.join(train_l) + '\\n')\n",
    "    valid.write('\\n'.join(valid_l) + '\\n')\n",
    "    test.write('\\n'.join(test_l) + '\\n')\n",
    "    print 'Finished'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datetime.strptime('2016-01-09T17:00:00', '%Y-%m-%dT%H:%M:%S')\n",
    "s = '2016-01-03T00:00:00,2016-04-23,2016-05-20'\n",
    "(datetime.now() - datetime.strptime('2016-01-09T17:00:00', '%Y-%m-%dT%H:%M:%S')).total_seconds() / ONE_DAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.concatenate((np.array([1, 2]), [3])).tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
